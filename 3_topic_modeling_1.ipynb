{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import pyLDAvis.gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim import corpora, models\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from pprint import pprint\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Tweets to Categories\n",
    "<a id=\"intertopic_map\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA - Intertopic Distance Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines = pd.read_csv('./data/with_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(airlines.lemmatized.str.split())\n",
    "\n",
    "# Create Corpus\n",
    "texts = airlines.lemmatized.str.split()\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=3, \n",
    "                                           random_state=42,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=500,\n",
    "                                           passes=90,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.011*\"\\'one\\',\" + 0.010*\"\\'ticket\\',\" + 0.009*\"\\'new\\',\" + '\n",
      "  '0.009*\"\\'seat\\',\" + 0.008*\"\\'cancelled\\',\" + 0.006*\"\\'first\\',\" + '\n",
      "  '0.006*\"\\'american\\',\" + 0.005*\"\\'travel\\',\" + 0.005*\"\\'problem\\',\" + '\n",
      "  '0.005*\"\\'delta\\',\"'),\n",
      " (1,\n",
      "  '0.014*\"\\'plane\\',\" + 0.012*\"\\'time\\',\" + 0.011*\"\\'hour\\',\" + '\n",
      "  '0.010*\"\\'bag\\',\" + 0.008*\"\\'delayed\\',\" + 0.007*\"\\'max\\',\" + '\n",
      "  '0.007*\"\\'delay\\',\" + 0.007*\"\\'gate\\',\" + 0.006*\"\\'boeing\\',\" + '\n",
      "  '0.006*\"\\'day\\',\"'),\n",
      " (2,\n",
      "  '0.011*\"\\'service\\',\" + 0.011*\"\\'customer\\',\" + 0.010*\"\\'u\\',\" + '\n",
      "  '0.007*\"\\'get\\',\" + 0.006*\"\\'would\\',\" + 0.006*\"\\'like\\',\" + '\n",
      "  '0.005*\"\\'make\\',\" + 0.005*\"\\'home\\',\" + 0.005*\"\\'know\\',\" + '\n",
      "  '0.005*\"\\'help\\',\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the keywords in the topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(airlines['text'])]\n",
    "\n",
    "#  building a model\n",
    "model = Doc2Vec(documents, vector_size=300, window=5, min_count=1, dm =1)\n",
    "#Infer vector for a new document:\n",
    "vector = model.infer_vector([\"system\", \"response\"])\n",
    "#vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_doc = model.docvecs.most_similar(3,topn = 50)\n",
    "similar_doc.sort(key= lambda x: x[1])\n",
    "similar_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.iloc[[i[0] for i in similar_doc],:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
